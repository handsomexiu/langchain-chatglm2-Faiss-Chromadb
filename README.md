# langchain_chatglm2-6b_Faiss

æœ¬æ¬¡é¡¹ç›®å®éªŒæ—¨åœ¨é’ˆå¯¹chatglm2 è®¾è®¡webuiï¼Œå¹¶æ„å»ºçŸ¥è¯†åº“,é¡¹ç›®ä¸»è¦å‚è€ƒäº†[thomas-yanxin/LangChain-ChatGLM-Webui: åŸºäºLangChainå’ŒChatGLM-6Bç­‰ç³»åˆ—LLMçš„é’ˆå¯¹æœ¬åœ°çŸ¥è¯†åº“çš„è‡ªåŠ¨é—®ç­” (github.com)](https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui)çš„è®¾è®¡ï¼Œä½†æ˜¯é‡‡ç”¨çš„æœ€æ–°çš„ä¸€äº›åŒ…ï¼ŒåŒæ—¶è€ƒè™‘ä¸åŒçš„æ–‡æ¡£åˆ’åˆ†æ–¹å¼ä»¥åŠä¸åŒçš„çŸ¥è¯†åº“æ„å»ºã€‚

åŒæ—¶å®ç°å¤šæ–‡ä»¶çš„ä¸Šä¼ ä»¥åŠå‘é‡åŒ–çš„å¤„ç†ã€‚

è€ƒè™‘ çš„çŸ¥è¯†åº“ä¸ºï¼šfaiss(å‚è€ƒé¡¹ç›®[1]ä¸­æ‰€é‡‡ç”¨çš„)ï¼Œchromadbï¼ˆå‚è€ƒé¡¹ç›®[2]æ‰€é‡‡ç”¨çš„ï¼‰å’Œmilvus(è¿˜æ²¡æœ‰å®ç°)ã€‚



# æ–‡ä»¶å¤¹è¯´æ˜

1. ç›´æ¥æ”¾åœ¨æœ€å¤–è·¯å¾„çš„å‡ ä¸ªæ–‡ä»¶ï¼Œapp.pyç­‰æ˜¯é’ˆå¯¹çš„Faissæ•°æ®åº“
2. langchain_chromadb/milvusåˆ†åˆ«æ˜¯é’ˆå¯¹chromadbå’Œmilvusçš„å®éªŒ
3. æ–‡ä»¶å¤‡ä»½æ˜¯å¯¹æ—©æœŸä»£ç çš„ä¸€äº›å¤‡ä»½
4. ç¬”è®°æ˜¯æ€»ç»“çš„ä¸€äº›å°çŸ¥è¯†
5. model_cacheæ˜¯ä»langchain-chatglm-webuiè¿™ä¸ªé¡¹ç›®ä¸­æ‹·è´è¿‡æ¥çš„
6. tryæ˜¯åšçš„ä¸€äº›å°è¯•ï¼Œæ¯”è¾ƒæ‚ä¹±
7. vector_store æ˜¯å­˜å‚¨å‘é‡æ•°æ®åº“çš„åœ°æ–¹
8. knowledgeï¼šé‡Œé¢æ˜¯å­˜æ”¾å®éªŒç”¨çš„çŸ¥è¯†åº“æ–‡ä»¶åŒ…æ‹¬ï¼špdf,txt,docx,mdæ–‡ä»¶


# detectron2ï¼Œntlkå®‰è£…è¿‡ç¨‹
## detectron2

é¦–å…ˆ `git clone https://github.com/facebookresearch/detectron2.git`
ç„¶å `pip install -e detectron2``
ç­‰å¾…å®‰è£…å³å¯

åœ¨å‚è€ƒåˆ«äººçš„å®‰è£…æ–¹å¼ `pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2` å‡ºç°äº†å‡ ä¸ªé—®é¢˜
- linuxä¸ŠæŠ¥é”™è¯´æ‰¾ä¸åˆ°è¯¥æ–‡ä»¶
-  Windowsä¸ŠæŠ¥é”™ 'ERROR: Could not build wheels for detectron2, which is required to install pyproject.toml-based projects'

## ntlk

è¿™ä¸ªå®‰è£…çš„æ—¶å€™é¦–å…ˆéœ€è¦å®‰è£…ï¼š`pip intsall ntlk`

ç„¶åæ–‡ä»¶ä¸­æœ‰ä¸€ä¸ªntlk_dataçš„æ–‡ä»¶ï¼Œä½†æˆ‘åœ¨ipynbä¸­æ‰§è¡ŒUnstructuredFileLoader,loadä¸€ä¸‹çš„æ—¶å€™å°±æŠ¥é”™

```
[nltk_data] Error loading punkt: [WinError 10060] 
[nltk_data]     ç”±äºè¿æ¥æ–¹åœ¨ä¸€æ®µæ—¶é—´åæ²¡æœ‰æ­£ç¡®ç­”å¤æˆ–è¿æ¥çš„ä¸»æœºæ²¡æœ‰ååº”ï¼Œè¿æ¥å°è¯•å¤±è´¥ã€‚
```

åº”è¯¥æ˜¯æ²¡æœ‰searchåˆ°æ–‡ä»¶ä¸­çš„ntlk_dataæ–‡ä»¶

åé¢æˆ‘æ‰§è¡Œäº†tryæ–‡ä»¶ä¸­çš„try.pyæ–‡ä»¶ï¼Œåœ¨æˆ‘çš„cç›˜ä¸‹é¢è‡ªåŠ¨è£…äº†ä¸€ä¸ªï¼Œç„¶åå°±æ²¡æœ‰æŠ¥é”™äº†

```python
import re
from typing import List
from langchain.document_loaders.unstructured import UnstructuredFileLoader
from langchain.text_splitter import CharacterTextSplitter
loader = UnstructuredFileLoader(
    "try/1.pdf", strategy="fast", mode="elements"
)
docs = loader.load()
```

æˆ–è€…ç›´æ¥åœ¨ä»£ç ä¸­æ·»åŠ 

```python
nltk.data.path = [os.path.join(os.path.dirname(__file__), "nltk_data")
                  ] + nltk.data.path
```

# æ³¨æ„
1. gradio==3.50.2,æœ€æ–°çš„ç‰ˆæœ¬4.0.2æœ‰é—®é¢˜ï¼ŒæŠ¥é”™ï¼š PermissionError: [WinError 32] å¦ä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œè¿›ç¨‹æ— æ³•è®¿é—®ã€‚ä¸çŸ¥é“ä¸ºä»€ä¹ˆä¼šè¿™æ ·

2. gradioç‰ˆæœ¬å¤ªä½å¦‚gradio==3.23.0ï¼Œä¹Ÿä¼šæŠ¥é”™ï¼šTypeError: __init__() got an unexpected keyword argument 'shape'

3. æœåŠ¡å™¨ç§Ÿç”¨çš„æ˜¯AutoDLçš„A5000ï¼Œæ˜¾å­˜24Gï¼Œå†…å­˜30G

4. transformer==4.30.2ï¼Œå¦‚æœå®‰è£…æœ€æ–°çš„ç‰ˆæœ¬ï¼ˆ2023.11.2å®‰è£…çš„æ—¶å€™ç‰ˆæœ¬æ˜¯4/34.1ï¼‰å¯èƒ½å›æœ‰é—®é¢˜ï¼Œæœ‰äº›åº“å•¥çš„æ²¡æœ‰
   1. AttributeError: 'ChatGLMTokenizer' object has no attribute 'tokenizer'
   2. è§£å†³æ–¹æ¡ˆï¼šé™ä½ç‰ˆæœ¬å¦‚4.30.1ï¼ˆè¿™ä¹Ÿæ˜¯chatglm2-6b githubä¸­ requirementsä¸­å†™çš„ï¼‰ï¼Œæˆ–è€…æ›´æ–°tokenization_chatglm.pyï¼ˆæš‚æ—¶æ²¡æœ‰å°è¯•è¿‡ï¼‰ï¼š[AttributeError: 'ChatGLMTokenizer' object has no attribute 'tokenizer' Â· Issue #1835 Â· chatchat-space/Langchain-Chatchat (github.com)](https://github.com/chatchat-space/Langchain-Chatchat/issues/1835)

5. æ–‡ä»¶ä¸­çš„ï¼šfrpc_linux_amd64_v0.2ï¼Œè¿™ä¸ªæ˜¯ç”¨æ¥ä¸ºgradioåˆ›å»ºå¤–éƒ¨é“¾æ¥çš„

   1. å¯¹frpc_linux_amd64_v0.2è¿›è¡Œæ‰§è¡Œèƒ½åŠ›èµ‹äºˆ chmod +x
      			1. å¦‚æœæ²¡æœ‰åˆ›å»ºè™šæ‹Ÿç¯å¢ƒçš„è¯ï¼Œè·¯å¾„ä¸€èˆ¬æ˜¯ï¼š/root/miniconda3/lib/python3.8/site-packages/gradio/ï¼ˆå…·ä½“çœ‹minicondaçš„å®‰è£…ä½ç½®
   2. [ã€Gradioã€‘Could not create share link-CSDNåšå®¢](https://blog.csdn.net/unp/article/details/131479915)

6. è¦å…ˆåŠ è½½çŸ¥è¯†ï¼Œç„¶åå†å‘é‡åŒ–ï¼Œæœ€åæ‰èƒ½é—®é—®é—®é—®é¢˜

   ```python
   #åœ¨app.pyæ–‡ä»¶ä¸­ KnowledgeBasedChatLLMçš„get_knowledge_based_answeræ–¹æ³•ä¸­
   def get_knowledge_based_answer(self,
                                  query,
                                  top_k: int = 6,
                                  history_len: int = 3,
                                  temperature: float = 0.01,
                                  top_p: float = 0.1,
                                  history=[]):
       self.llm.temperature = temperature
       self.llm.top_p = top_p
       self.history_len = history_len
       self.top_k = top_k
       prompt_template = """åŸºäºä»¥ä¸‹å·²çŸ¥ä¿¡æ¯ï¼Œè¯·ç®€æ´å¹¶ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
               å¦‚æœæ— æ³•ä»ä¸­å¾—åˆ°ç­”æ¡ˆï¼Œè¯·è¯´ "æ ¹æ®å·²çŸ¥ä¿¡æ¯æ— æ³•å›ç­”è¯¥é—®é¢˜" æˆ– "æ²¡æœ‰æä¾›è¶³å¤Ÿçš„ç›¸å…³ä¿¡æ¯"ã€‚ä¸å…è®¸åœ¨ç­”æ¡ˆä¸­æ·»åŠ ç¼–é€ æˆåˆ†ã€‚å¦å¤–ï¼Œç­”æ¡ˆè¯·ä½¿ç”¨ä¸­æ–‡ã€‚
   
               å·²çŸ¥å†…å®¹:
               {context}
   
               é—®é¢˜:
               {question}"""
       prompt = PromptTemplate(template=prompt_template,
                               input_variables=["context", "question"])
       self.llm.history = history[
           -self.history_len:] if self.history_len > 0 else []
       vector_store = FAISS.load_local(f'{VECTOR_STORE_PATH}/faiss_index', self.embeddings)
       #è¿™é‡Œå°±æ„å‘³ç€è¦å…ˆæœ‰æ–‡ä»¶çš„è¾“å…¥ä»¥åŠå‘é‡åŒ–ï¼šfaiss_index,æ‰èƒ½è¿›è¡Œé—®ç­”ï¼Œä¸ç„¶å°±ä¼šæŠ¥é”™
   
       knowledge_chain = RetrievalQA.from_llm(# æ£€ç´¢é—®ç­”é“¾
           llm=self.llm,
           retriever=vector_store.as_retriever(
               search_kwargs={"k": self.top_k}),
           prompt=prompt)
       knowledge_chain.combine_documents_chain.document_prompt = PromptTemplate(
           input_variables=["page_content"], template="{page_content}")
   
       knowledge_chain.return_source_documents = True
   
       result = knowledge_chain({"query": query})
       return result
   # å¦‚æœæ²¡æœ‰æŒ‰è¯´æ˜çš„é¡ºåºå°±ä¼šæŠ¥é”™
   >>> RuntimeError: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open vector_store/faiss_index/index.faiss for reading: No such file or directory
   
   ```

7. ~~æ³¨æ„åœ¨gradioä¸­çš„inputä¸­æœ€å¤šåªèƒ½æœ‰6ä¸ªå‚æ•°ï¼Œå› æ­¤è¿™é‡Œæ²¡æœ‰è€ƒè™‘ä»chatglmçš„max_lengthå‚æ•°~~

   1. ~~'\# /root/miniconda3/lib/python3.8/site-packages/gradio/utils.py:820: UserWarning: Expected maximum 6 arguments for function <function predict at 0x7f3b82df9c10>, received 7.'~~
   1. è¿™é‡Œæ˜¯æ²¡æœ‰ä¿®æ”¹predictçš„å‚æ•°ï¼Œæ²¡æœ‰é—®é¢˜

8. è¦å®ç°å¤šä¸ªæ–‡ä»¶çš„ä¸Šä¼ ï¼Œéœ€è¦ä¿®æ”¹gr.Fileä¸­çš„å‚æ•° file_count='multiple'

   ```
   file = gr.File(label='è¯·ä¸Šä¼ çŸ¥è¯†åº“æ–‡ä»¶',
                   file_types=['.txt', '.md', '.docx', '.pdf'],
                   file_count='multiple')
   ```

   1. è¯¥å‚æ•°æœ‰ä¸‰ä¸ªå€¼*'single', 'multiple', 'directory'*ï¼Œé»˜è®¤æ˜¯singleï¼Œè¡¨ç¤ºä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶ï¼›multipleè¡¨ç¤ºä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼›directoryï¼šè¡¨ç¤ºä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶å¤¹ç›®å½•ï¼Œä¸Šä¼ é‡Œé¢çš„æ‰€æœ‰æ–‡ä»¶
      1. å¤šä¸ªæ–‡ä»¶è¿”å›çš„æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼š[<tempfile._TemporaryFileWrapper object at 0x7f5ab3f395b0>, <tempfile._TemporaryFileWrapper object at 0x7f59e248a670>]ï¼Œä¸€ä¸ª<>è¡¨ç¤ºä¸€ä¸ªæ–‡ä»¶
      2. å•ä¸ªæ–‡ä»¶ç›´æ¥è¿”å›çš„æ˜¯ <tempfile._TemporaryFileWrapper object at 0x7f59e248a670>
         1. å¯¹äºå•ä¸ªæ–‡ä»¶å¯ä»¥é€šè¿‡.name è®¿é—®æ–‡ä»¶çš„åœ°å€ï¼Œï¼š/tmp/gradio/d7370fdd9ab92219d8e33f82c2fb68c39d7274fb/æ·±åº¦å­¦ä¹ .txtï¼Œè¿™æ˜¯ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ã€‚ä½†æ–‡ä»¶åå’Œ
            1. å…·ä½“å¯ä»¥å‚è€ƒgradio Filesçš„typeå‚æ•°[Gradio File Docs](https://www.gradio.app/docs/file)
      3. æ³¨æ„ï¼šå¦‚æœç”¨directoryä¼šè­¦å‘Šï¼š/root/miniconda3/lib/python3.8/site-packages/gradio/components/file.py:103: UserWarning: The\`file_types\` parameter is ignored when \`file_count` is 'directory'.
         1. ä½†æ˜¯è¿™é‡Œå¯ä»¥ç›´æ¥ç”¨ï¼Œdirectoryå°±æ˜¯å°†æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶å…¨éƒ¨ä¼ å…¥ï¼Œå’Œmultipleä¸€æ ·éƒ½æ˜¯list

9. å¦‚æœè¦ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼Œè¿˜éœ€è¦å¯¹å‘é‡æ•°æ®åº“éƒ¨åˆ†è¿›è¡Œå¤„ç†ï¼Œå¦‚ä½•å¤„ç†å¤šä¸ªå‘é‡ï¼Œå¦‚ä½•å¯¼å…¥å¤šä¸ªå‘é‡

   1. [langchain.vectorstores.faiss.FAISS â€” ğŸ¦œğŸ”— LangChain 0.0.329](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html#langchain.vectorstores.faiss.FAISS.from_documents)
      1. *classmethod* **from_documents**(*documents: List[[Document](https://api.python.langchain.com/en/latest/schema/langchain.schema.document.Document.html#langchain.schema.document.Document)]*, *embedding: [Embeddings](https://api.python.langchain.com/en/latest/schema/langchain.schema.embeddings.Embeddings.html#langchain.schema.embeddings.Embeddings)*, ***kwargs: Any*) â†’ VSTï¼ˆå‘é‡å­˜å‚¨æ–¹å¼å¦‚IVFï¼ŒPQï¼‰
   
      2. è€ƒè™‘åˆ°from_documentsæ¥å—çš„æ˜¯[document]
   
         1. è¿™é‡Œåˆ©ç”¨if+isinstanceæ¥åˆ¤æ–­ä¼ ç»™init_knowledge_vector_storeæ˜¯å¦æ˜¯åˆ—è¡¨
         2. å¯¹äºå•ä¸ªæ–‡ä»¶ç›´æ¥ä¸Šä¼ 
         3. å¤šä½™å¤šä¸ªæ–‡ä»¶ï¼Œåˆ©ç”¨å¾ªç¯+åˆ—è¡¨çš„æ–¹æ³•extendæ¥å°†ä¸åŒæ–‡ä»¶çš„documentå­˜åœ¨ä¸€ä¸ªlistä¸­ã€‚
   
      3. ```python
         if isinstance(file_obj, list):
             docs=[]
             for file in file_obj:
                 doc=self.load_file(file.name)
                 docs.extend(doc)#è¿™é‡Œä¸åŒäºappendï¼Œextendæ˜¯å°†åˆ—è¡¨ä¸­çš„å…ƒç´ æ·»åŠ åˆ°å¦ä¸€ä¸ªåˆ—è¡¨ä¸­
         else:
             docs = self.load_file(file_obj.name)
         ```
   
         



# é¡¹ç›®å‚è€ƒ

[1] [thomas-yanxin/LangChain-ChatGLM-Webui: åŸºäºLangChainå’ŒChatGLM-6Bç­‰ç³»åˆ—LLMçš„é’ˆå¯¹æœ¬åœ°çŸ¥è¯†åº“çš„è‡ªåŠ¨é—®ç­” (github.com)](https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui)

[2] [IronSpiderMan/MachineLearningPractice: æœºå™¨å­¦ä¹ å®æˆ˜æ¡ˆä¾‹ï¼Œæ¶‰åŠæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ç­‰å„ä¸ªæ–¹å‘ã€‚æ¯ä¸ªæ¡ˆä¾‹ä»£ç é‡åœ¨ç™¾è¡Œå·¦å³ã€‚ (github.com)](https://github.com/IronSpiderMan/MachineLearningPractice)

# ç»“æœå±•ç¤º

æ¨¡å‹åŠ è½½

![image-20231113112751040](F:\å¤§æ¨¡å‹æºç \å®æˆ˜\try1_practice1+2\img\Faiss_æ¨¡å‹åŠ è½½.png)

å¤šæ–‡ä»¶åŠ è½½ï¼Œä»¥åŠåŸºäºçŸ¥è¯†åº“çš„é—®ç­”

![image-20231113113018587](F:\å¤§æ¨¡å‹æºç \å®æˆ˜\try1_practice1+2\img\Faiss_é—®ç­”.png)



# å‘é‡æ•°æ®åº“

è¿™é‡Œçš„å‘é‡æ•°æ®åº“ä»…å±€é™äºpython åŒ…çš„å®‰è£…ï¼ˆä¹Ÿå°±æ˜¯åˆ©ç”¨pythonè¿›è¡Œæ“ä½œï¼‰ï¼Œè¿˜æ²¡æœ‰å‘é‡æ•°æ®åº“çš„éƒ¨ç½²ï¼Œå‘é‡æ•°æ®åº“çš„éƒ¨ç½²è¿˜å¾—ç”¨dockerï¼Œè‡³äºè¿™ä¸ªéƒ¨ç½²å’Œç»´æŠ¤è¿˜å¾—ç»§ç»­å­¦ä¹ 
milvusæ˜¯è¦dockerçš„