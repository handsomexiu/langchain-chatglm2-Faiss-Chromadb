{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "# 这里是为了能偶访问到非当前文件夹中的包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.trychroma.com/getting-started\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/658217843\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "# from langchain.document_loaders import TextLoader#这个有一点问题\n",
    "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
    "import sentence_transformers\n",
    "import torch\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from config import *\n",
    "from typing import List\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChineseTextSplitter(CharacterTextSplitter):\n",
    "    def __init__(self, pdf: bool = False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pdf = pdf\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        if self.pdf:\n",
    "            text = re.sub(r\"\\n{3,}\", \"\\n\", text)\n",
    "            text = re.sub('\\s', ' ', text)\n",
    "            text = text.replace(\"\\n\\n\", \"\")\n",
    "        sent_sep_pattern = re.compile(\n",
    "            '([﹒﹔﹖﹗．。！？][\"’”」』]{0,2}|(?=[\"‘“「『]{1,2}|$))') \n",
    "        sent_list = []\n",
    "        for ele in sent_sep_pattern.split(text):\n",
    "            if sent_sep_pattern.match(ele) and sent_list:\n",
    "                sent_list[-1] += ele\n",
    "            elif ele:\n",
    "                sent_list.append(ele)\n",
    "        return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"1.pdf\"\n",
    "loader = UnstructuredFileLoader(filepath)\n",
    "textsplitter = ChineseTextSplitter(pdf=True)\n",
    "docs = loader.load_and_split(textsplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='未来预测的一个关键挑战是高度的不确定性，这在很大程度上是由于不知道其他代理的意图和潜在  特征。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='例如，车辆通常具有多模态的未来分布：它可以转弯、直行、减速、加速等。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='根据其他场景元  素，它可以通过、让行、改变车道或驶入车道。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='在过去的几年里，这一挑战引起了很多人的兴趣。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='对高  度多模态进行建模的一种方法是采用可以从中抽取样本的灵活隐式分布——条件变分自动编码器(CVAEs)  [1]、生成对抗网络(GANs)[2]、和单步策略推出方法[3]。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='尽管它们的表现具有竞争力，但使用隐变量来  建模意图会阻止它们被解释，并且通常需要测试时间抽样来评估概率查询（例如，“代理向左转的可能性  有多大？”', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='）。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='此外，在大型机器学习社区[4]中，特别是自动驾驶汽车中，已经有相当大的努力来解决这  类模型中的模式崩溃问题[5,6]。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='  为了解决这些限制，我们观察到，对于我们的任务（例如车辆和行人轨迹预测），在较长的未来中  的不确定性主要可以通过对代理可能目标的预测来捕获。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='这些目标不仅基于可解释的物理实体（例如位  置），而且与意图密切相关（例如变道或右转）。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='我们推测目标空间可以在场景中被离散化——允许确  定性模型并行生成不同的目标——并且后来改进得更精确了。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='  这些观察导致我们提出了目标驱动轨迹预测框架，名为 TNT。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='我们首先将未来预测问题转化为预测  在离散目标上的分布状态，然后制定一个概率模型，其中轨迹估计和可能性是基于这样的目标。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='生成的  框架有三个端到端训练的阶段：（1）目标预测 估计给定场景背景下的候选目标上的分布；（2）以目标  为条件的移动估计 预测每个目标的轨迹状态序列；（3）评分和选择 估计每个预测轨迹的可能性，并考  虑所有其他预测轨迹的背景。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='我们通过排序可能性和抑制冗余的轨迹最终得到了一系列紧凑的多样预  测。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='我们三个阶段模型的说明应用于车辆轨迹预测如图1所示。', metadata={'source': '1.pdf'}),\n",
       " Document(page_content='尽管我们的模型是端到端训练的，但是它  的三个阶段的布局，在每个阶段都有可解释的输出，紧密遵循了传统机器人运动预测和规划系统的典型  处理步骤 [7, 8]，因此，很容易在部署期间合并领域知识。', metadata={'source': '1.pdf'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '1.pdf'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'未来预测的一个关键挑战是高度的不确定性，这在很大程度上是由于不知道其他代理的意图和潜在  特征。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_dict = embedding_model_dict\n",
    "llm_model_dict = llm_model_dict\n",
    "EMBEDDING_DEVICE = EMBEDDING_DEVICE\n",
    "LLM_DEVICE = LLM_DEVICE\n",
    "num_gpus = num_gpus#GPU数量\n",
    "large_language_model = init_llm\n",
    "embedding_model=init_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一步加载成功\n",
      "embedding模型加载成功\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'F:/大模型源码/embedding/text2vec-base-chinese_old'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HuggingFaceEmbeddings(model_name=embedding_model_dict[embedding_model], )\n",
    "print('第一步加载成功')\n",
    "model.client = sentence_transformers.SentenceTransformer(\n",
    "            model.model_name,\n",
    "            device=EMBEDDING_DEVICE,\n",
    "            cache_folder=os.path.join(MODEL_CACHE_PATH,model.model_name))\n",
    "print('embedding模型加载成功')\n",
    "# 这里相当于是对client属性进行赋值，尽管在__init__huggingface中已经赋值了，但是没全\n",
    "'''\n",
    "        self.client = sentence_transformers.SentenceTransformer(\n",
    "            self.model_name, cache_folder=self.cache_folder, **self.model_kwargs\n",
    "        )\n",
    "\n",
    "'''\n",
    "model.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = Chroma.from_documents(docs, model,persist_directory=\"../langchain_chromadb/vector_store/chroma_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb\n",
    "# from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "# chroma_client = chromadb.Client()\n",
    "\n",
    "# # 这里创建数据不用langchain\n",
    "# # 这里是对一个一个向量数据库\n",
    "# class MyEmbeddingFunction(EmbeddingFunction):\n",
    "#     def __call__(self, texts: Documents) -> Embeddings:\n",
    "#         embeddings = [model.embed_query(x.page_content) for x in texts]\n",
    "#         return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the open-source embedding function\n",
    "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids=[f'id{i+1}' for i in range(len(docs))]\n",
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # collection 需要确定id\n",
    "# collection.add(\n",
    "#     documents=docs,\n",
    "#     # metadata=metadata,\n",
    "#     ids=ids\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
